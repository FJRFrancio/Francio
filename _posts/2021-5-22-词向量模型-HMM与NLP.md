---
layout: post
title: 词向量模型，HMM与NLP
tags: 
- HMM
- NLP
- Python
categories: Python
---



# 词向量模型，HMM与NLP


## 词分布表达
- PMI向量：词与上下文词的出现概率（互信息向量）
    - 得到相似度矩阵后可以继续降维，得到k维实空间向量表达，得到词矩阵
- 神经网络实现的词向量表达：可实现词向量的加减
- LSA：隐含语义挖掘，词对文档的分布降维后SVD，转成K维再转回词向量
- NNLM
- CBOW模型：将上下文的词向量通过一个变换到隐含层，投影到另一个向量中，通过sigmoid函数产生一个词表中所有词的概率分布，再与标准答案作LOSS，反向传播训练模型
- skip-gram：输入一个词，通过分类器判断是不是所需上下文词，等驾驭PMI向量特征空间的降维表达，多了一个偏置值


### 词向量：Gensim库
- 处理得到词文档集，每句一个列表，列表中元素为各词
- 向量相似度：使用cos夹角作为特征间距，避开了文章长度的影响，不用归一化
- PMI可以用点乘
- Gensim：基于矩阵分解的词汇-文档空间表示模型与应用接口集合
- 

### NLP
- NLTK：常用包，可以将词和句子分成token，附带停用词表
    - 自带"概念"数，一个"概念"叶子节点里包含与这个概念相关的词


### 中文分词与HMM模型
- 中文词与词间没有显式标志与表示词语的分界
- 切分歧义与交集型歧义
- 未登录词的问题：结合紧密，使用稳定，整体意不等于部分意的多字组
    - 利用字间互相预测的概率，概率更大的字间更有可能是同一个词
    - 句法映射：两字向量相加可映射到组合的词
    - 但凡能被句法分析器中理解的词不能放到词典中，不认为它是一个词
- 如何分词：
    - 基于字符串匹配
    - 基于统计
    - 基于理解

### 基于统计的分词
#### 语言模型与概率图分词
- 一句话中n个字，设置n+1个切分点，切分点间连通构成概率加权图，求解最优概率
- 词序列是否合：看成句可能性大小如何，（注意是合理性不是正确性）
- 语言模型：在某些词出现的条件下，下一个词为某特定词的概率（如CBOW模型）
- 一个分词结果是否合理，看他在语言模型中被生成的概率大小
- 时间序列：上面模型的词间有顺序，每一个词的出现概率与前面的词有关
- 马尔可夫假设：词的出现概率仅与前面一个词有关（二元模型）
    - 句子过长，信息稀疏，模型可能变差
- 统计模型：在已经人工标注的数据集前计算上面的各词间条件概率，用于计算当前分词结果的概率最大路径
- 

####  HMM与标注问题
- HMM：想像出的内部运行模式，可以回归出内部隐含状态间转移的方式，隐状态可以被学出来
- 隐变量间有马尔可夫链，同时存在一个发射矩阵，可以生成观测序列 
- 认为观测序列间没有直接的关系，只跟隐变量有关
- 评价模型：向前算法
- 解码：寻找最大概率隐状态序列（模型已知，回归隐状态序列 9）
- Viterbi算法
- 词性标注：HMM
- Jieba分词：输入UTF-8

- jieba:cut返回一个generator，lcut返回列表
- nltk：hasattr：查看是否有label
- nltk：tree2conlltags：tree转元组                                                                                                                       



